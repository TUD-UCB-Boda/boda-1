#ifdef GLSL
layout (local_size_x = __wg_sz__, local_size_y = 1, local_size_z = 1) in;
layout(set = 0, binding = 0) readonly buffer filts_t{
  float filts[];
};
layout(set = 0, binding = 1) readonly buffer in_buf_t{
  float in_buf[];
};
layout(set = 0, binding = 2) buffer out_buf_t{
  float out_buf[];
};

layout (set = 0, binding = 3) buffer POD
{
  int work;
};

shared float filts_sm[%(filts_sm_sz)];
shared float in_buf_sm[%(in_buf_sm_sz)];
void main()
#else
CUCL_GLOBAL_KERNEL void %(rtc_func_name)( GASQ float const * const filts, // CUCL IN K:M
					  GASQ float const * const in_buf, // CUCL IN K:N
					  GASQ float * const out_buf,  // CUCL OUT M:N
					  GASQ void const * const work )  // CUCL REF Mg:Ng:Mb:Nb:Kb:Mt:Nt
#endif
{
  // CUCL IX GRP_ID_1D work use_dims=Mg:Ng
  // CUCL IX LOC_ID_1D work use_dims=Mb:Nb
  // note: <each thread handles> work use_dims=Mt:Nt output points;loops over K with unrollingfactor of Kb
  // FIXME: for now, we assume Kb == 1
  #ifdef GLSL
  float out_buf_r[%(work_Mt_dim)*%(work_Nt_dim)]; // tile of output for this thread to compute, stored in registers
  for (int i = 0; i < %(work_Mt_dim)*%(work_Nt_dim); i++)
      out_buf_r[i] = 0.0;
  #else
  LOCSHAR_MEM float filts_sm[%(filts_sm_sz)];
  LOCSHAR_MEM float in_buf_sm[%(in_buf_sm_sz)];
  float out_buf_r[%(work_Mt_dim)*%(work_Nt_dim)] = {0}; // tile of output for this thread to compute, stored in registers
  #endif
  float filts_r[%(work_Mt_dim)]; 
  float in_buf_r[%(work_Nt_dim)];

  // block-level constant offsets into a + b, each plus the thread id (LOC_ID_1D), for shared-memory loading
  uint32_t filts_off = %(GRP_ID_1D_Mg)*%(work_Mb_dim)*%(work_Mt_dim)*%(filts_M_stride) + LOC_ID_1D;
  const uint32_t  in_buf_off_base = %(GRP_ID_1D_Ng)*%(work_Nb_dim)*%(work_Nt_dim)*%(in_buf_N_stride) + LOC_ID_1D;
    
  const uint32_t filts_sm_off = %(LOC_ID_1D_Mb)*%(work_Mt_dim);
  const uint32_t in_buf_sm_off = %(LOC_ID_1D_Nb)*%(work_Nt_dim);

  uint32_t in_buf_off = in_buf_off_base;
  //LSMASQ %(filts_tn) * const filts_sm_off = filts_sm + %(LOC_ID_1D_Mb)*%(work_Mt_dim)*%(work_Kb_dim) + %(LOC_ID_1D_Nb);
  for( int32_t k = 0; k < %(filts_K_dim); k += %(work_Kb_dim) ) {
    //in_buf_off = in_buf_off_base + k*%(work_Kb_dim)*%(in_buf_K_stride); // FIXME: adding this line fixes 512x512 case on SD820 ...
    BARRIER_SYNC;
    %(sm_loads);
    filts_off += %(work_Kb_dim)*%(filts_K_stride);
    in_buf_off += %(work_Kb_dim)*%(in_buf_K_stride);
    BARRIER_SYNC; 
    %(inner_loop_body);
  }

  uint32_t out_buf_off = // thread-level offset into c
    (%(GRP_ID_1D_Mg)*%(work_Mb_dim)+%(LOC_ID_1D_Mb))*%(work_Mt_dim)*%(out_buf_M_stride) + 
    (%(GRP_ID_1D_Ng)*%(work_Nb_dim)+%(LOC_ID_1D_Nb))*%(work_Nt_dim)*%(out_buf_N_stride);

  for( int32_t Mt = 0; Mt < %(work_Mt_dim); ++Mt ) {
    %(outs_to_in_buf_r);
    %(stores);
    out_buf_off += %(out_buf_M_stride);
  }

}
