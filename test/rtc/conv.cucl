CUCL_GLOBAL_KERNEL void %(rtc_func_name)( GASQ float const * const filts, // CUCL IN out_chan_blk:in_chan:y:x:out_chan_reg:out_chan_tile
					  GASQ float const * const biases, // CUCL IN out_chan
					  GASQ float const * const in, // CUCL IN img:chan:y:x
					  GASQ float * const out,  // CUCL OUT img:chan:y:x
                                          GASQ void const * const stride, // CUCL REF y:x
                                          GASQ void const * const in_pad, // CUCL REF y:x
                                          GASQ void const * const work ) // CUCL REF pels_blk:out_chan_blk:pels_tile:out_chan_tile:pels:out_chan
{
  // CUCL IX out_pel_ix out use_dims=img:y:x
  // CUCL IX filts_ix_out_chan_elem filts use_dims=in_chan:y:x
  // CUCL IX GRP_ID_1D work use_dims=pels_blk:out_chan_blk
  // CUCL IX LOC_ID_1D work use_dims=pels_tile:out_chan_tile
  // note: <each thread handles> work use_dims=pels:out_chan; with pels_stride==out_chan_stride==t_tile_sz (currently); loops over in.chan==filts.in_chan
  LOCSHAR_MEM float in_smem[%(work_pels_tile_dim)*%(work_pels_dim)];
  LOCSHAR_MEM float filts_smem[%(filts_smem_sz)];
  float out_tile[%(work_pels_dim)*%(work_out_chan_dim)] = {0}; // tile of output for this thread to compute, stored in registers
  // reg. buffers for one strip each from in and filts, for the same filts_ix_out_chan_elem
  float filts_strip[%(work_out_chan_dim)]; // across output chans (stride is %(filts_smem_sz) )
  float in_strip[%(work_pels_dim)]; // across pels (approx square block in x/y space, favoring x if sqrt() not integer)

  int32_t const blk_pel_ix_sz = %(work_pels_tile_dim)*%(work_pels_dim);
  int32_t const blk_pel_ix_base = %(GRP_ID_1D_pels_blk)*blk_pel_ix_sz;
  // iteratate over filter elements
  int32_t filts_off = %(GRP_ID_1D_out_chan_blk)*%(filts_out_chan_blk_stride) + LOC_ID_1D; // index of first out chan (for this block) + LOC_ID_1D
  for( int32_t filts_ix_out_chan_elem = 0; filts_ix_out_chan_elem != 
	 (%(filts_in_chan_dim) * %(filts_x_dim) * %(filts_y_dim)); ++filts_ix_out_chan_elem ) {
    BARRIER_SYNC;
    %(filts_smem_loads);
    for( int32_t i = 0; i != %(pel_smem_load_iter); ++i ) {
      if( (LOC_ID_1D+LOC_SZ_1D*i) < blk_pel_ix_sz ) { 
	int32_t const out_pel_ix = (blk_pel_ix_base+LOC_ID_1D+LOC_SZ_1D*i);
        
        int const smem_in_ix_y = %(out_pel_ix_y) * %(stride_y_dim) + %(filts_ix_out_chan_elem_y) - %(in_pad_y_dim);
        int const smem_in_ix_x = %(out_pel_ix_x) * %(stride_x_dim) + %(filts_ix_out_chan_elem_x) - %(in_pad_x_dim);
        if(smem_in_ix_y >= 0 && smem_in_ix_x >= 0 && %(out_pel_ix_img) < %(in_img_dim) && smem_in_ix_x < %(in_x_dim) && smem_in_ix_y < %(in_y_dim) ) {
          in_smem[LOC_ID_1D+LOC_SZ_1D*i] = in[%(out_pel_ix_img) * %(in_img_stride) + %(filts_ix_out_chan_elem_in_chan) * %(in_chan_stride) + smem_in_ix_y * %(in_y_stride) + smem_in_ix_x * %(in_x_stride)];
  	}
      }
    }
    filts_off += %(filts_x_stride);
    BARRIER_SYNC;
    %(loads);
    %(fmas);
  }
  // load per-block biases into smem
  BARRIER_SYNC;
  %(biases_smem_loads);
  BARRIER_SYNC;
  // load biases into filts_strip
  %(loads);
  // add bias to each elem of out_tile[] and store the results to out[]
  %(stores);
}

